{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40fcc7364e6c0c0",
   "metadata": {},
   "source": [
    "# Data Augmentation Pipeline\n",
    "\n",
    "Done with albumentations library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c323171a98f23",
   "metadata": {},
   "source": [
    "## Imports and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T12:52:19.899482Z",
     "start_time": "2025-10-24T12:52:19.893376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "src = Path(\"cow-hooves\")\n",
    "dst = Path(\"augmented-cow-hooves\")\n",
    "img_paths = fs.ls(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc367377027501",
   "metadata": {},
   "source": [
    "## Compose Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51746abc9e2eb3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T12:52:19.909688Z",
     "start_time": "2025-10-24T12:52:19.898804Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomResizedCrop(size=(1440, 1080), scale=(0.8, 1.0), ratio=(0.75, 1.33), p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.15,\n",
    "        scale_limit=0.2,\n",
    "        rotate_limit=25,\n",
    "        border_mode=0,\n",
    "        p=0.9\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a41523dff9711ca",
   "metadata": {},
   "source": [
    "## Augment Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359f580662af22ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T12:52:20.675217Z",
     "start_time": "2025-10-24T12:52:19.904189Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: augmented-cow-hooves/0_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/0_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/0_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/0_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/0_flir_20251012T134100.jpg\n",
      "Saved: augmented-cow-hooves/1_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/1_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/1_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/1_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/1_flir_20251012T134100.jpg\n",
      "Saved: augmented-cow-hooves/2_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/2_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/2_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/2_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/2_flir_20251012T134100.jpg\n",
      "Saved: augmented-cow-hooves/3_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/3_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/3_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/3_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/3_flir_20251012T134100.jpg\n",
      "Saved: augmented-cow-hooves/4_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/4_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/4_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/4_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/4_flir_20251012T134100.jpg\n",
      "Saved: augmented-cow-hooves/5_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/5_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/5_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/5_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/5_flir_20251012T134100.jpg\n",
      "Saved: augmented-cow-hooves/6_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/6_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/6_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/6_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/6_flir_20251012T134100.jpg\n",
      "Saved: augmented-cow-hooves/7_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/7_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/7_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/7_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/7_flir_20251012T134100.jpg\n",
      "Saved: augmented-cow-hooves/8_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/8_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/8_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/8_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/8_flir_20251012T134100.jpg\n",
      "Saved: augmented-cow-hooves/9_flir_20251012T132854.jpg\n",
      "Saved: augmented-cow-hooves/9_flir_20251012T133121.jpg\n",
      "Saved: augmented-cow-hooves/9_flir_20251012T133405.jpg\n",
      "Saved: augmented-cow-hooves/9_flir_20251012T133511.jpg\n",
      "Saved: augmented-cow-hooves/9_flir_20251012T134100.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for img_path in img_paths:\n",
    "        # Read image bytes from GCS\n",
    "        with fs.open(img_path, \"rb\") as f:\n",
    "            img_bytes = f.read()\n",
    "\n",
    "        # Decode bytes to numpy array (OpenCV image)\n",
    "        image = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Apply your transform\n",
    "        augmented = transform(image=image)\n",
    "        aug_img = augmented[\"image\"]\n",
    "\n",
    "        # Prepare save path\n",
    "        image_name = f\"{i}_{img_path.split('/')[-1]}\"\n",
    "        save_path = f\"{dst}/{image_name}\"\n",
    "\n",
    "        # Encode the image to bytes before saving\n",
    "        success, encoded_img = cv2.imencode(\".jpg\", cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "        if success:\n",
    "            with fs.open(save_path, \"wb\") as f:\n",
    "                f.write(encoded_img.tobytes())\n",
    "\n",
    "        print(f\"saved: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
